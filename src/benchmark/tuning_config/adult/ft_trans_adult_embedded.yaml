program: run_benchmark.py
project: tjepa-sweeps
name: fttransformer_adult_embedded_sweep_v2
method: bayes
metric:
  goal: maximize
  name: adult_embedded_val_accuracy
parameters:
  model_name:
    value: "fttransformer"
  data_set:
    value: "adult_embedded"
  data_path:
    value: "./datasets"
  data_loader_nprocs:
    value: 4
  exp_cadence_type:
    value: "improvement"
  exp_train_total_epochs:
    value: 200
  batch_size:
    value: 512
  exp_warmup:
    value: 10
  lr:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-2
  exp_final_lr:
    value: 0
  final_weight_decay:
    value: 0
  start_lr:
    value: 0
  weight_decay:
    min: 1e-7
    max: 1e-3
    distribution: log_uniform_values
  test_size_ratio:
    value: 0.1
  val_size_ratio:
    value: 0.1
  exp_cache_cadence:
    value: 20
  exp_patience:
    value: 16
  using_embedding:
    value: True
  encoder_type:
    values:
      ["linear_flatten", "linear_per_feature", "conv", "max_pool", "mean_pool"]
  n_blocks:
    values: [2, 4, 6, 8, 10, 12, 16]
  d_block:
    values: [32, 64, 128, 256, 512]
  attention_n_heads:
    values: [2, 4, 8, 16]
  attention_dropout:
    min: 0.0
    max: 0.5
  ffn_d_hidden:
    values: [32, 64, 128, 256, 512]
  ffn_dropout:
    min: 0.0
    max: 0.5
  residual_dropout:
    min: 0.0
    max: 0.2
